{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from dataset import MELDDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from a \".tar.gz\" file. Put the content into data/name_of_file folder\n",
    "def extract_data(file_name, data_folder):\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    tar = tarfile.open(file_name, \"r:gz\")\n",
    "    tar.extractall(data_folder)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(data_folder):\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        # for all videos in the folder, remove \"._\" at the beginning of the file name\n",
    "        for file in files:\n",
    "            if file.startswith('._'):\n",
    "                os.rename(os.path.join(root, file), os.path.join(root, file[2:]))\n",
    "            \n",
    "rename_files('./data/test/video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_data(\"data/raw/test.tar.gz\", \"data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_valid_corrupted_videos(folder_path, extensions=(\"mp4\", \"mov\", \"mkv\", \"avi\")):\n",
    "    \"\"\"\n",
    "    Filters out corrupted video files in a specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing video files.\n",
    "        extensions (tuple): Allowed video file extensions to check (default: common formats).\n",
    "\n",
    "    Returns:\n",
    "        valid_videos (list): List of valid video file paths.\n",
    "        corrupted_videos (list): List of corrupted or invalid video file paths.\n",
    "    \"\"\"\n",
    "    valid_videos = []\n",
    "    corrupted_videos = []\n",
    "\n",
    "    # Get all video files in the folder with the specified extensions\n",
    "    video_files = [file for ext in extensions for file in Path(\n",
    "        folder_path).rglob(f\"*.{ext}\")]\n",
    "\n",
    "    for video_path in video_files:\n",
    "        # Convert Path object to string (for subprocess compatibility)\n",
    "        video_path = str(video_path)\n",
    "\n",
    "        # Run ffprobe to check the video file\n",
    "        try:\n",
    "            command = [\n",
    "                \"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "                \"-of\", \"default=noprint_wrappers=1:nokey=1\", video_path\n",
    "            ]\n",
    "            result = subprocess.run(\n",
    "                command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                # If ffprobe runs successfully and returns a duration, the video is valid\n",
    "                duration = result.stdout.strip()\n",
    "                if duration:  # If duration is not empty\n",
    "                    valid_videos.append(video_path)\n",
    "                else:\n",
    "                    corrupted_videos.append(video_path)\n",
    "            else:\n",
    "                # If ffprobe fails, the video is considered corrupted\n",
    "                print(f\"Corrupted video detected: {video_path}\")\n",
    "                corrupted_videos.append(video_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch unexpected errors\n",
    "            print(f\"Error processing file {video_path}: {e}\")\n",
    "            corrupted_videos.append(video_path)\n",
    "\n",
    "    return valid_videos, corrupted_videos\n",
    "\n",
    "def delete_corrupted_videos(videos_paths, csv_path):\n",
    "    \"\"\"\n",
    "    Deletes corrupted video files from the specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing video files.\n",
    "        videos_paths (list): List of corrupted video file paths.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for video_path in videos_paths:\n",
    "        try:\n",
    "            os.remove(video_path)\n",
    "            print(f\"Deleted corrupted video: {video_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {video_path}: {e}\")\n",
    "            \n",
    "        # Remove the corresponding row from the dataframe\n",
    "        # by first extracting dialogue and utterance IDs from the file path\n",
    "        # (naming: dia{dialogue_id}_utt{utterance_id}.mp4)\n",
    "        dialogue_id = int(video_path.split(\"dia\")[1].split(\"_\")[0])\n",
    "        utterance_id = int(video_path.split(\"utt\")[1].split(\".\")[0])\n",
    "        df = df.drop(df[(df[\"Dialogue_ID\"] == dialogue_id) & (df[\"Utterance_ID\"] == utterance_id)].index)\n",
    "        \n",
    "    # Save the updated dataframe\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "def rename_test_videos(data_folder):\n",
    "    # if a video has the prefix \"final_videos_test\" remove it\n",
    "    for root, dirs, files in os.walk(data_folder):\n",
    "        for file in files:\n",
    "            if file.startswith('t'):\n",
    "                os.rename(os.path.join(root, file), os.path.join(root, file[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid videos: 554\n",
      "Corrupted videos: 0\n"
     ]
    }
   ],
   "source": [
    "valid_videos, corrupted_videos = count_valid_corrupted_videos(\n",
    "    'data/test/video')\n",
    "print(f\"Valid videos: {len(valid_videos)}\")\n",
    "print(f\"Corrupted videos: {len(corrupted_videos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the corrupted videos\n",
    "delete_corrupted_videos(corrupted_videos, 'data/test/test_sent_emo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the csv file: 554\n",
      "Number of valid videos: 554\n"
     ]
    }
   ],
   "source": [
    "# check the df have the same number of lines as the number of valid videos\n",
    "df = pd.read_csv('data/test/test_sent_emo.csv')\n",
    "print(f\"Number of lines in the csv file: {len(df)}\")\n",
    "print(f\"Number of valid videos: {len(valid_videos)}\")\n",
    "\n",
    "# check which one are missing\n",
    "for video_path in valid_videos:\n",
    "    # Extract dialogue and utterance IDs from the file path\n",
    "    dialogue_id = int(video_path.split(\"dia\")[1].split(\"_\")[0])\n",
    "    utterance_id = int(video_path.split(\"utt\")[1].split(\".\")[0])\n",
    "\n",
    "    # Check if the dialogue and utterance IDs are in the dataframe\n",
    "    if not ((df[\"Dialogue_ID\"] == dialogue_id) & (df[\"Utterance_ID\"] == utterance_id)).any():\n",
    "        print(f\"Missing: {video_path}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the videos that are not in the csv file\n",
    "for video_path in valid_videos:\n",
    "    # Extract dialogue and utterance IDs from the file path\n",
    "    dialogue_id = int(video_path.split(\"dia\")[1].split(\"_\")[0])\n",
    "    utterance_id = int(video_path.split(\"utt\")[1].split(\".\")[0])\n",
    "\n",
    "    # Check if the dialogue and utterance IDs are in the dataframe\n",
    "    if not ((df[\"Dialogue_ID\"] == dialogue_id) & (df[\"Utterance_ID\"] == utterance_id)).any():\n",
    "        os.remove(video_path)\n",
    "        print(f\"Deleted: {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataset\n",
    "dataset = MELDDataset(\n",
    "    csv_file=\"data/test/test_sent_emo.csv\",\n",
    "    root_dir=\"data/test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_array': array([-0.00198962, -0.02142128, -0.02587057, ..., -0.06124197,\n",
       "        -0.06868309, -0.0437346 ], dtype=float32),\n",
       " 'sampling_rate': 22050,\n",
       " 'transcript': 'also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system.',\n",
       " 'emotion': 'neutral',\n",
       " 'sentiment': 'neutral'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "emotions = dataset.get_emotions_list()\n",
    "model = MultimodalClassifier(num_classes=len(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset.get_emotions_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'neutral', 'positive'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset.get_sentiments_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
